{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### NOTE: Search for \"### FILL IN ###\" to find areas of problem that you are expected to work on."
      ],
      "metadata": {
        "id": "SJ6DcaRsASZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "k6B5Un-XXEPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "#seed everything for reproducability\n",
        "def seed_everything(seed=1234):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything()\n"
      ],
      "metadata": {
        "id": "QMH1G7vUMNch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART A: CNN [70 POINTS]**"
      ],
      "metadata": {
        "id": "AJFn1ts4Suvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1: CNN basics [30 POINTS]**\n",
        "\n",
        "\n",
        "The convolution function takes in an image, a kernel, a stride, and a padding size, and returns the output of the convolution operation. The image and kernel are numpy arrays, where image is of shape (height, width, channels) and kernel is of shape (kernel_height, kernel_width, channels, num_filters). The stride and padding are integers that specify the stride size and padding size, respectively.\n",
        "\n",
        "<br>\n",
        "\n",
        "Note that this implementation will assume that the input image has a depth of channels and that the kernel has the same depth. \n",
        "\n",
        "<br>\n",
        "\n",
        "Apply convolution operation on the input image with the specified kernel, stride, and padding.\n",
        "\n",
        "It takes arguments\n",
        "\n",
        "    - image: numpy array of shape (height, width, channels)\n",
        "    - kernel: numpy array of shape (kernel_height, kernel_width, channels, num_filters)\n",
        "    - stride: integer, the stride size\n",
        "    - padding: integer, the padding size\n",
        "\n",
        "and returns\n",
        "\n",
        "    - numpy array of shape (output_height, output_width, num_filters)"
      ],
      "metadata": {
        "id": "dSc8_7_xFYRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution(image, kernel, stride, padding):\n",
        "    height, width, channels = image.shape\n",
        "    kernel_height, kernel_width, _, num_filters = kernel.shape\n",
        "\n",
        "    ### FILL IN ### [5 POINTS]\n",
        "    # Calculate output shape\n",
        "    output_height = \n",
        "    output_width = \n",
        "\n",
        "    ### FILL IN ### [5 POINTS]\n",
        "    # Add padding to the image if any\n",
        "    if padding > 0:\n",
        "        image_padded = \n",
        "    else:\n",
        "        image_padded = \n",
        "\n",
        "    ### FILL IN ### [10 POINTS]\n",
        "    # Initialize output array\n",
        "    output = np.zeros((output_height, output_width, num_filters))\n",
        "    # Apply convolution\n",
        "\n",
        "    return output\n"
      ],
      "metadata": {
        "id": "XjEhm4PqEl3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download sample image from OpenCV repository\n",
        "url = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/data/board.jpg'\n",
        "filename = 'sample_image.jpg'\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "id": "HNIbeOnJWe5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### you should see sample_image.jpg present\n",
        "\n",
        "! ls"
      ],
      "metadata": {
        "id": "r5EEbrHfWoyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sample image\n",
        "image = cv2.imread('sample_image.jpg')\n",
        "cv2_imshow(image)"
      ],
      "metadata": {
        "id": "Z7_SD1_BXSaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.shape"
      ],
      "metadata": {
        "id": "tA6iZKeogSBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_1 = np.zeros((3, 3, 3))\n",
        "\n",
        "kernel_1[:,:,0] = kernel_1[:,:,1] = kernel_1[:,:,2] = np.array([[[1, 0, -1],\n",
        "                                                                [1, 0, -1],\n",
        "                                                                [1, 0, -1]]])\n",
        "\n",
        "kernel_1 = kernel_1.reshape(3, 3, 3, 1)"
      ],
      "metadata": {
        "id": "ng1-Oxpmb64P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply convolution with stride=1 and padding=1\n",
        "output_1 = convolution(image, kernel_1, stride=1, padding=1)\n",
        "cv2_imshow(output_1)"
      ],
      "metadata": {
        "id": "HVAcD6Srb6wB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply convolution with stride=3 and padding=1\n",
        "output_1b = convolution(image, kernel_1, stride=3, padding=1)\n",
        "cv2_imshow(output_1b)"
      ],
      "metadata": {
        "id": "xRBcch_Lf4TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### restoring the size to see differences\n",
        "output_1c = cv2.resize(output_1b, (image.shape[1], image.shape[0])) \n",
        "cv2_imshow(output_1c)"
      ],
      "metadata": {
        "id": "wmp5z8r6hOtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kernel_2 = np.zeros((3, 3, 3))\n",
        "\n",
        "kernel_2[:,:,0] = kernel_2[:,:,1] = kernel_2[:,:,2] = np.array([[1, 1, 1],\n",
        "                                                                [0, 0, 0],\n",
        "                                                                [-1, -1, -1]])\n",
        "\n",
        "kernel_2 = kernel_2.reshape(3, 3, 3, 1)"
      ],
      "metadata": {
        "id": "8ZJYCmSQeJPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply convolution with stride=1 and padding=1\n",
        "output_2 = convolution(image, kernel_2, stride=1, padding=1)\n",
        "cv2_imshow(output_2)"
      ],
      "metadata": {
        "id": "KPUqPNTYeJPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"### FILL IN ###\" [3 POINTS]\n",
        "\n",
        "What is the operation kernel_1 responsible for?\n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n",
        "\n",
        "\"### FILL IN ###\" [3 POINTS]\n",
        "\n",
        "What is the operation kernel_2 responsible for?\n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n",
        "\n",
        "\"### FILL IN ###\" [4 POINTS]\n",
        "\n",
        "As seen in output_1b and output_1c , what happens when we increase the stride value ? \n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n"
      ],
      "metadata": {
        "id": "gaR3omclh2JU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2: CNN vs ANN [40 POINTS]**\n",
        "\n",
        "Let's consider the MNIST dataset, which contains images of handwritten digits. Each image is 28 pixels wide and 28 pixels tall, for a total of 784 pixels. The task is to classify each image into one of ten possible classes (0-9).\n",
        "\n",
        "<br>\n",
        "\n",
        "In the Menu, change runtime type to GPU for faster computations"
      ],
      "metadata": {
        "id": "kuMxG-DbjSOg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W58mt0lP2VPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "VxsKY6DT6kOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Define data loaders\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "YoK8Om-Q2pgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a batch of images from the data loader\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "# Plot the images\n",
        "fig, axs = plt.subplots(4, 8, figsize=(10, 5))\n",
        "\n",
        "for i in range(4):\n",
        "    for j in range(8):\n",
        "        axs[i, j].imshow(np.squeeze(images[i*8+j]), cmap='gray')\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ca81Vvp-2pYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network model \n",
        "# Use single hidden layer of 128 nodes\n",
        "# Use ReLU activation\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        ### FILL IN ### [5 POINTS]\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### FILL IN ### [5 POINTS]\n",
        "        \n",
        "        return x"
      ],
      "metadata": {
        "id": "YEnibGTc6hal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the convolutional neural network model \n",
        "# Use first convolution layer of 32 filters of size of 3x3 and a stride of 1\n",
        "# Use second convolution layer of 64 filters of size of 3x3 and a stride of 1\n",
        "# Use max pooling layer with kernel size of 2x2 and a stride of 2.\n",
        "# Use single hidden layer of 128 nodes\n",
        "# Use ReLU activation\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        ### FILL IN ### [10 POINTS]\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ### FILL IN ### [5 POINTS]\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "MNuhqOcuFhbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize models and optimizer\n",
        "neural_net = NeuralNet().to(device)\n",
        "conv_net = ConvNet().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "neural_net_optimizer = optim.Adam(neural_net.parameters(), lr=0.001)\n",
        "conv_net_optimizer = optim.Adam(conv_net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "QWVhUmgt0Xf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the neural network\n",
        "for epoch in range(5):\n",
        "    print(\"epoch = \",epoch)\n",
        "    neural_net.train()\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        neural_net_predictions = neural_net(data)\n",
        "        neural_net_loss = criterion(neural_net_predictions, targets)\n",
        "\n",
        "        # Backward pass\n",
        "        neural_net_optimizer.zero_grad()\n",
        "        neural_net_loss.backward()\n",
        "        neural_net_optimizer.step()\n",
        "\n",
        "    # Evaluate the neural network\n",
        "    neural_net.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in test_loader:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "            neural_net_predictions = neural_net(data)\n",
        "            _, predicted = torch.max(neural_net_predictions.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    print(\"test accuracy = \",correct/total)"
      ],
      "metadata": {
        "id": "DAinQ1dD0T2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the convolutional neural network\n",
        "for epoch in range(5):\n",
        "    print(\"epoch = \",epoch)\n",
        "    conv_net.train()\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        conv_net_predictions = conv_net(data)\n",
        "        conv_net_loss = criterion(conv_net_predictions, targets)\n",
        "\n",
        "        # Backward pass\n",
        "        conv_net_optimizer.zero_grad()\n",
        "        conv_net_loss.backward()\n",
        "        conv_net_optimizer.step()\n",
        "\n",
        "    # Evaluate the conv neural network\n",
        "    conv_net.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data, targets in test_loader:\n",
        "            data = data.to(device)\n",
        "            targets = targets.to(device)\n",
        "            conv_net_predictions = conv_net(data)\n",
        "            _, predicted = torch.max(conv_net_predictions.data, 1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    print(\"test accuracy = \",correct/total)"
      ],
      "metadata": {
        "id": "4Oqi6ZguvdCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing some lateral shifts in these images and see performance differences"
      ],
      "metadata": {
        "id": "so9MR8NN8Wkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get a batch of images from the data loader\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "# Plot the images\n",
        "fig, axs = plt.subplots(3, 3, figsize=(5, 5))\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        axs[i, j].imshow(np.squeeze(images[i*8+j]), cmap='gray')\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xw4btFa02LFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformation\n",
        "shifted_transform = transforms.Compose([\n",
        "                    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2)),\n",
        "                    transforms.ToTensor(),\n",
        "                ])\n",
        "\n",
        "test_shifted_dataset = datasets.MNIST(root='./data', train=False, transform=shifted_transform)\n",
        "test_shifted_loader = torch.utils.data.DataLoader(test_shifted_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "jfp7dt042K-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of images from the data loader\n",
        "images, labels = next(iter(test_shifted_loader))\n",
        "\n",
        "# Plot the images\n",
        "fig, axs = plt.subplots(3, 3, figsize=(5, 5))\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        axs[i, j].imshow(np.squeeze(images[i*8+j]), cmap='gray')\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v3jznHMX3NpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neural_net.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_shifted_loader:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "        neural_net_predictions = neural_net(data)\n",
        "        _, predicted = torch.max(neural_net_predictions.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print(\"test accuracy = \",correct/total)"
      ],
      "metadata": {
        "id": "xuueO47d6Kx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_shifted_loader:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "        conv_net_predictions = conv_net(data)\n",
        "        _, predicted = torch.max(conv_net_predictions.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print(\"test accuracy = \",correct/total)"
      ],
      "metadata": {
        "id": "XuELJawr6KtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying shifts of higher magnitude "
      ],
      "metadata": {
        "id": "zR90EaCloPVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformation\n",
        "shifted_transform = transforms.Compose([\n",
        "                    transforms.RandomAffine(degrees=0, translate=(0.4, 0.4)),\n",
        "                    transforms.ToTensor(),\n",
        "                ])\n",
        "\n",
        "test_shifted_dataset = datasets.MNIST(root='./data', train=False, transform=shifted_transform)\n",
        "test_shifted_loader = torch.utils.data.DataLoader(test_shifted_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "kKhw66bb9ZhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of images from the data loader\n",
        "images, labels = next(iter(test_shifted_loader))\n",
        "\n",
        "# Plot the images\n",
        "fig, axs = plt.subplots(3, 3, figsize=(5, 5))\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        axs[i, j].imshow(np.squeeze(images[i*8+j]), cmap='gray')\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZkyAKlk29ZhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neural_net.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_shifted_loader:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "        neural_net_predictions = neural_net(data)\n",
        "        _, predicted = torch.max(neural_net_predictions.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print(\"test accuracy = \",correct/total)"
      ],
      "metadata": {
        "id": "l-4c3jJ09ZhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_net.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_shifted_loader:\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "        conv_net_predictions = conv_net(data)\n",
        "        _, predicted = torch.max(conv_net_predictions.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "print(\"test accuracy = \",correct/total)"
      ],
      "metadata": {
        "id": "_ACqqtwD9ZhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"### FILL IN ###\" [5 POINTS]\n",
        "\n",
        "Report final performances of NN and CNN on basic MNIST test data. \n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n",
        "\n",
        "\"### FILL IN ###\" [5 POINTS]\n",
        "\n",
        "Which one of the two models is better on shifted MNIST test data [2 POINTS] and why [3 POINTS] ?\n",
        "\n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n",
        "\n",
        "\"### FILL IN ###\" [5 POINTS]\n",
        "\n",
        "We noted that the performance dropped when the images are shifted. In order to make the model more robust can we train the model on both the original and shifted images ?\n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n"
      ],
      "metadata": {
        "id": "O1AFXKnN-Hjh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PART B: RNN [30 POINTS]**"
      ],
      "metadata": {
        "id": "csuQegx6DBDE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3: RNN vs LSTM [30 POINTS]**\n",
        "\n",
        "\n",
        "In this example, we first load the Penn Treebank dataset using the imdb dataset from Keras. We then pad the sequences to a fixed length of 100 and build two models, one with a SimpleRNN layer and the other with an LSTM layer. \n",
        "\n",
        "We then train both models for 10 epochs using the RMSprop optimizer and binary cross-entropy loss function. After training, we evaluate the performance of both models on the test set using the evaluate method.\n"
      ],
      "metadata": {
        "id": "z95Dw2NADBDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, SimpleRNN, Dense, Embedding\n",
        "from tensorflow.keras.models import Sequential\n",
        "tf.set_random_seed(1234)\n",
        "# Load the Penn Treebank dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=10000)"
      ],
      "metadata": {
        "id": "iim6XLEJcLCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the word index dictionary\n",
        "word_index = tf.keras.datasets.imdb.get_word_index()\n",
        "\n",
        "# Reverse the word index dictionary\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "metadata": {
        "id": "Qolu1d5hh-8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having a look at some samples"
      ],
      "metadata": {
        "id": "AGpk0KURlFCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 4th record in training data (integers are word indices)\n",
        "\n",
        "print(x_train[4])"
      ],
      "metadata": {
        "id": "P6fEE3_-cM5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index[10]"
      ],
      "metadata": {
        "id": "9iQUxNPPi8Aa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the review text for this record\n",
        "review_text = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_train[4]])\n",
        "review_text"
      ],
      "metadata": {
        "id": "G1KgymIniS2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(review_text.split()), len(x_train[4])"
      ],
      "metadata": {
        "id": "rtJ1XY7iio7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### corresponding label for 4th record in training data (0=negative,1=positive for movie reviews)\n",
        "y_train[4]"
      ],
      "metadata": {
        "id": "99Tg4dGVcMSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### looking at a positive moview review \n",
        "y_train[400]"
      ],
      "metadata": {
        "id": "BMXpz099jZAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_text = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_train[400]])\n",
        "review_text"
      ],
      "metadata": {
        "id": "vmLFTInJjgWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the sequences to a fixed length\n",
        "max_len = 100\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "uTlK3U0icwWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a SimpleRNN model\n",
        "# Use an embedding layer with an output dimension of 128\n",
        "# Use a single output layer with a sigmoid activation function\n",
        "# Add optimizer and loss as mentioned above\n",
        "\n",
        "### FILL IN ### [5 POINTS]\n",
        "model_rnn = \n",
        "model_rnn.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the SimpleRNN model\n",
        "model_rnn.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
      ],
      "metadata": {
        "id": "WShPXKXSc1uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build an LSTM model\n",
        "# Use an embedding layer with an output dimension of 128\n",
        "# Use a single output layer with a sigmoid activation function\n",
        "# Add optimizer and loss as mentioned above\n",
        "\n",
        "### FILL IN ### [5 POINTS]\n",
        "model_lstm = \n",
        "model_lstm.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the LSTM model\n",
        "model_lstm.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.2)"
      ],
      "metadata": {
        "id": "NeMWa3AMcIDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"### FILL IN ###\" [5 POINTS]\n",
        "\n",
        "Report final performances of RNN and LSTM on IMDB validation data. \n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n",
        "\n",
        "\"### FILL IN ###\" [5 POINTS]\n",
        "\n",
        "Which one of the two models is better on IMDB validation ?[2 POINTS] State one disadvantage of using LSTM over traditional RNN ? [3 POINTS]\n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n",
        "\n",
        "\"### FILL IN ###\" [5 POINTS]\n",
        "\n",
        "What is a Long Short-Term Memory (LSTM) network? [2 POINTS] How does it differ from a traditional RNN? [3 POINTS] \n",
        "\n",
        "\n",
        "\n",
        "Answer: \n",
        "\n",
        "<hr>\n",
        "\n",
        "\"### FILL IN ###\" [5 POINTS]\n",
        "\n",
        "What are Seq2Vec [2 POINTS], Vec2Seq [2 POINTS] and Seq2Seq [1 POINTS] models?\n",
        "\n",
        "Answer: "
      ],
      "metadata": {
        "id": "MfqzJvu4hdZC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6ZimS47KewYb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}